<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="X-Clacks-Overhead" content="GNU Terry Pratchett" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link rel="shortcut icon" href="/images/favicon.png" />
<title>Fishy Affine Transformation | sysid blog</title>
<meta name="title" content="Fishy Affine Transformation" />
<meta name="description" content="Fishy Affine Transformation While working on the kaggle competition https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring I hit the point when I wanted to align fish based on an annotation at the fish&rsquo;s head and tail, so that the fish is centered in the image, always in the same orientation and distracting picture information is minimized. This required:
finding the fish (thanks Nathaniel Shimoni for annotating) centering rotatating cropping Mathematically the challenge is to find the associated Affine Transformation." />
<meta name="keywords" content="python,math,machine learning,ai," />


<meta property="og:title" content="Fishy Affine Transformation" />
<meta property="og:description" content="Fishy Affine Transformation While working on the kaggle competition https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring I hit the point when I wanted to align fish based on an annotation at the fish&rsquo;s head and tail, so that the fish is centered in the image, always in the same orientation and distracting picture information is minimized. This required:
finding the fish (thanks Nathaniel Shimoni for annotating) centering rotatating cropping Mathematically the challenge is to find the associated Affine Transformation." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/fishy-affine-transformation/" /><meta property="og:image" content="images/share.png"/><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2017-03-13T22:12:03+00:00" />
<meta property="article:modified_time" content="2017-03-13T22:12:03+00:00" /><meta property="og:site_name" content="sysid blog" />



<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="images/share.png"/>

<meta name="twitter:title" content="Fishy Affine Transformation"/>
<meta name="twitter:description" content="Fishy Affine Transformation While working on the kaggle competition https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring I hit the point when I wanted to align fish based on an annotation at the fish&rsquo;s head and tail, so that the fish is centered in the image, always in the same orientation and distracting picture information is minimized. This required:
finding the fish (thanks Nathaniel Shimoni for annotating) centering rotatating cropping Mathematically the challenge is to find the associated Affine Transformation."/>



<meta itemprop="name" content="Fishy Affine Transformation">
<meta itemprop="description" content="Fishy Affine Transformation While working on the kaggle competition https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring I hit the point when I wanted to align fish based on an annotation at the fish&rsquo;s head and tail, so that the fish is centered in the image, always in the same orientation and distracting picture information is minimized. This required:
finding the fish (thanks Nathaniel Shimoni for annotating) centering rotatating cropping Mathematically the challenge is to find the associated Affine Transformation."><meta itemprop="datePublished" content="2017-03-13T22:12:03+00:00" />
<meta itemprop="dateModified" content="2017-03-13T22:12:03+00:00" />
<meta itemprop="wordCount" content="834"><meta itemprop="image" content="images/share.png"/>
<meta itemprop="keywords" content="python,math,machine learning,ai," />
<meta name="referrer" content="no-referrer-when-downgrade" />

  <style>
  body {
    font-family: Verdana, sans-serif;
    margin: auto;
    padding: 20px;
    max-width: 720px;
    text-align: left;
    background-color: #fff;
    word-wrap: break-word;
    overflow-wrap: break-word;
    line-height: 1.5;
    color: #444;
  }

  h1,
  h2,
  h3,
  h4,
  h5,
  h6,
  strong,
  b {
    color: #222;
  }

  a {
    color: #3273dc;
     
  }

  .title {
    text-decoration: none;
    border: 0;
  }

  .title span {
    font-weight: 400;
  }

  nav a {
    margin-right: 10px;
  }

  textarea {
    width: 100%;
    font-size: 16px;
  }

  input {
    font-size: 16px;
  }

  content {
    line-height: 1.6;
  }

  table {
    width: 100%;
  }

  img {
    max-width: 100%;
  }

  code {
    padding: 2px 5px;
    background-color: #f2f2f2;
  }

  pre code {
    color: #222;
    display: block;
    padding: 20px;
    white-space: pre-wrap;
    font-size: 14px;
    overflow-x: auto;
  }

  div.highlight pre {
    background-color: initial;
    color: initial;
  }

  div.highlight code {
    background-color: unset;
    color: unset;
  }

  blockquote {
    border-left: 1px solid #999;
    color: #222;
    padding-left: 20px;
    font-style: italic;
  }

  footer {
    padding: 25px;
    text-align: center;
  }

  .helptext {
    color: #777;
    font-size: small;
  }

  .errorlist {
    color: #eba613;
    font-size: small;
  }

   
  ul.blog-posts {
    list-style-type: none;
    padding: unset;
  }

  ul.blog-posts li {
    display: flex;
  }

  ul.blog-posts li span {
    flex: 0 0 130px;
  }

  ul.blog-posts li a:visited {
    color: #8b6fcb;
  }

  @media (prefers-color-scheme: dark) {
    body {
      background-color: #333;
      color: #ddd;
    }

    h1,
    h2,
    h3,
    h4,
    h5,
    h6,
    strong,
    b {
      color: #eee;
    }

    a {
      color: #8cc2dd;
    }

    code {
      background-color: #777;
    }

    pre code {
      color: #ddd;
    }

    blockquote {
      color: #ccc;
    }

    textarea,
    input {
      background-color: #252525;
      color: #ddd;
    }

    .helptext {
      color: #aaa;
    }
  }

</style>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-8VH574W51S"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-8VH574W51S', { 'anonymize_ip': false });
}
</script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@4.0.0-alpha.1/es5/tex-mml-chtml.js"></script>


<script>
    MathJaxDone = new Promise((resolve, reject) => {
        window.MathJax = {
            tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]},
            startup: {
                pageReady() {
                    return MathJax.startup.defaultPageReady().then(resolve);
                }
            }
        }
    });
</script>

</head>

<body>
  <header><a href="/" class="title">
  <h2>sysid blog</h2>
</a>
<nav><a href="/">Home</a>

<a href="/tools">Tools</a>


<a href="/blog">Blog</a>

</nav>
</header>
  <main>

<h1>Fishy Affine Transformation</h1>
<p>
  <i>
    <time datetime='2017-03-13' pubdate>
      13 Mar, 2017
    </time>
  </i>
</p>

<content>
  <h1 id="fishy-affine-transformation">Fishy Affine Transformation</h1>
<p>While working on the kaggle competition <a href="https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring">https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring</a> I hit the point when I wanted
to align fish based on an annotation at the fish&rsquo;s head and tail, so that the fish is centered in the image, always in the same orientation
and distracting picture information is minimized. This required:</p>
<ol>
<li>finding the fish (thanks Nathaniel Shimoni for annotating)</li>
<li>centering</li>
<li>rotatating</li>
<li>cropping</li>
</ol>
<p>Mathematically the challenge is to find the associated  Affine Transformation. After years of working in a managerial role my linear algebra skills are a bit rusty so I decided to
invest the weekend.</p>
<h3 id="affine-transformation">Affine Transformation</h3>
<p><a href="http://mathworld.wolfram.com/AffineTransformation.html">Wolfram</a>: An affine transformation is any transformation that preserves collinearity (i.e., all points lying on a line initially still lie on a line after transformation) and ratios of distances (e.g., the midpoint of a line segment remains the midpoint after transformation).</p>
<p>I decided to use <a href="http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html#transformations">CV2</a> after hitting the wall with several other tools.
It was not the most convenient choice, but eventually it got me there. CV2 uses (2x3) transformation matrices for affine transformations so I had to adjust my 2d vectors accordingly.</p>
<p>The reason: Homogeneous Coordinates.</p>
<p>To combine rotation and translation in one operation one extra dimension is needed more than the model requires.
For planar things this is 3 components and for spatial things this is 4 components.
The operators take 3 components and return 3 components requiring 3x3 matrices.</p>
<p>Using vector algebra with numpy requires some extra consideration but is possible. Basically a (2,) matrix represented the 2-dim vectors. Small letters
denoted vector variables and caps matrices.</p>
<h2 id="1-finding-the-fish">1. Finding the Fish</h2>
<p>I used the annotations from labels produced by Nathaniel Shimoni and published on Kaggle (thanks for the great work!).</p>
<p>Using only fish with head and tail annotated, it was possible to get the vector representation of a fish as:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>p_heads = np.array((img_data[<span style="color:#d20;background-color:#fff0f0">&#39;annotations&#39;</span>][<span style="color:#00d;font-weight:bold">0</span>][<span style="color:#d20;background-color:#fff0f0">&#39;x&#39;</span>], img_data[<span style="color:#d20;background-color:#fff0f0">&#39;annotations&#39;</span>][<span style="color:#00d;font-weight:bold">0</span>][<span style="color:#d20;background-color:#fff0f0">&#39;y&#39;</span>]))
</span></span><span style="display:flex;"><span>p_tails = np.array((img_data[<span style="color:#d20;background-color:#fff0f0">&#39;annotations&#39;</span>][<span style="color:#00d;font-weight:bold">1</span>][<span style="color:#d20;background-color:#fff0f0">&#39;x&#39;</span>], img_data[<span style="color:#d20;background-color:#fff0f0">&#39;annotations&#39;</span>][<span style="color:#00d;font-weight:bold">1</span>][<span style="color:#d20;background-color:#fff0f0">&#39;y&#39;</span>]))
</span></span><span style="display:flex;"><span>p_middle = (p_heads + p_tails)/<span style="color:#00d;font-weight:bold">2</span>
</span></span><span style="display:flex;"><span>v_fish = p_heads - p_tails
</span></span></code></pre></div><h2 id="2-centering">2. Centering</h2>
<p>Centering fish is a basic translation in the 2-dim space.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#888"># translate to center of img</span>
</span></span><span style="display:flex;"><span>    img_center = np.array([img_height/<span style="color:#00d;font-weight:bold">2</span>, img_width/<span style="color:#00d;font-weight:bold">2</span>])
</span></span><span style="display:flex;"><span>    t = img_center - p_middle  <span style="color:#888"># translation vector</span>
</span></span><span style="display:flex;"><span>    t = np.reshape(t, (<span style="color:#00d;font-weight:bold">2</span>,<span style="color:#00d;font-weight:bold">1</span>))  <span style="color:#888"># generate the 2x3 affine transformation matrix</span>
</span></span><span style="display:flex;"><span>    T = np.concatenate((np.identity(<span style="color:#00d;font-weight:bold">2</span>), t), axis=<span style="color:#00d;font-weight:bold">1</span>)
</span></span></code></pre></div><p>The respective transformation matrix is:</p>
<figure class="center"><img src="fishy-affine-transformation-translation.png" width="100%"/>
</figure>

<h2 id="3-rotating">3. Rotating</h2>
<p>First I needed to find the angle for rotation. I wanted to have the fish oriented parallel to the x-axis with the head always being on the right. The dot-product of two vectors provides the
angle in between, so I had to &lsquo;dot-product&rsquo; my fish vector with the x-axis:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#080;font-weight:bold">def</span> <span style="color:#06b;font-weight:bold">unit_vector</span>(vector):
</span></span><span style="display:flex;"><span>    <span style="color:#d20;background-color:#fff0f0">&#34;&#34;&#34; Returns the unit vector of the vector.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#080;font-weight:bold">return</span> vector / np.linalg.norm(vector)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#080;font-weight:bold">def</span> <span style="color:#06b;font-weight:bold">angle_between</span>(v1, v2):
</span></span><span style="display:flex;"><span>    <span style="color:#d20;background-color:#fff0f0">&#34;&#34;&#34; Returns the angle in radians between vectors &#39;v1&#39; and &#39;v2&#39;::
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">            &gt;&gt;&gt; angle_between((1, 0, 0), (0, 1, 0))
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">            1.5707963267948966
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">            &gt;&gt;&gt; angle_between((1, 0, 0), (1, 0, 0))
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">            0.0
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">            &gt;&gt;&gt; angle_between((1, 0, 0), (-1, 0, 0))
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">            3.141592653589793
</span></span></span><span style="display:flex;"><span><span style="color:#d20;background-color:#fff0f0">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    v1_u = unit_vector(v1)
</span></span><span style="display:flex;"><span>    v2_u = unit_vector(v2)
</span></span><span style="display:flex;"><span>    <span style="color:#080;font-weight:bold">return</span> np.arccos(np.clip(np.dot(v1_u, v2_u), -<span style="color:#00d;font-weight:bold">1.0</span>, <span style="color:#00d;font-weight:bold">1.0</span>))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>angle = np.rad2deg(angle_between((<span style="color:#00d;font-weight:bold">1</span>, <span style="color:#00d;font-weight:bold">0</span>), v_fish))
</span></span></code></pre></div><p>Conveniently CV2 provides a function to find the necessary transformation matrix (cv2.getRotationMatrix2D).</p>
<p>A challenge was to find out, that the rotation angle returned always is between 0-180°, so the following conditional differentiation was necessary
(rotation counter clockwise vs clockwise). It basically differentiates between the case that the head is above or below the tail:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#888"># get the Affine transformation matrix</span>
</span></span><span style="display:flex;"><span>    <span style="color:#080;font-weight:bold">if</span> p_heads[<span style="color:#00d;font-weight:bold">1</span>] &gt; p_tails[<span style="color:#00d;font-weight:bold">1</span>]:  <span style="color:#888"># head is above tail</span>
</span></span><span style="display:flex;"><span>        M = cv2.getRotationMatrix2D((p_middle[<span style="color:#00d;font-weight:bold">0</span>], p_middle[<span style="color:#00d;font-weight:bold">1</span>]), angle, <span style="color:#00d;font-weight:bold">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#080;font-weight:bold">else</span>:
</span></span><span style="display:flex;"><span>        M = cv2.getRotationMatrix2D((p_middle[<span style="color:#00d;font-weight:bold">0</span>], p_middle[<span style="color:#00d;font-weight:bold">1</span>]), -angle, <span style="color:#00d;font-weight:bold">1</span>)
</span></span></code></pre></div><h2 id="putting-it-all-together">Putting it all together</h2>
<p>Getting the resulting transformation from a translation and rotation mathematically translates to a matrix product and applying the resulting
transformation matrix to the fish vector. To make the multiplication of a 2x3 tranlation matrix and a 2x3 rotation matrix possible the
following steps were necesary (combination of two affine transformations):</p>
<ul>
<li>allocate A1, A2, R matrices, all 3x3 identity matrices (eyes)</li>
<li>replace the top part of A1 and A2 with the transformation matrices T and M</li>
<li>get the resulting transformation (matrix product)</li>
<li>return the first two rows of R</li>
</ul>
<p>So RR was my final transformation matrix.</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    <span style="color:#888"># compinte affine transform: make them 3x3</span>
</span></span><span style="display:flex;"><span>    <span style="color:#888"># http://stackoverflow.com/questions/13557066/built-in-function-to-combine-affine-transforms-in-opencv</span>
</span></span><span style="display:flex;"><span>    A1 = np.identity(<span style="color:#00d;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span>    A2 = np.identity(<span style="color:#00d;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span>    R = np.identity(<span style="color:#00d;font-weight:bold">3</span>)
</span></span><span style="display:flex;"><span>    A1[:<span style="color:#00d;font-weight:bold">2</span>] = T
</span></span><span style="display:flex;"><span>    A2[:<span style="color:#00d;font-weight:bold">2</span>] = M
</span></span><span style="display:flex;"><span>    R = A1<span style="color:#555">@A2</span>
</span></span><span style="display:flex;"><span>    RR = R[:<span style="color:#00d;font-weight:bold">2</span>]
</span></span></code></pre></div><p>Getting the transformed image is now straightforward:</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>    dst = cv2.warpAffine(img, RR, (img_height, img_width))
</span></span></code></pre></div><p>The nice thing with this approach is that once you have got the final transformation matrix, all other points of interest can be transformed by this matrix,
e.g. the head and tail annotations are transformed by the same matrix.</p>
<h2 id="result">Result</h2>
<p>The blue point marks the head and the red point the tail. You can see the fish positioned arbitrarily in the image.
With the Affine Transformation the fish will be extracted and aligned.
The result is being displayed in the left upper corner.</p>
<figure class="center"><img src="fishy-affine-transformation-result.png" width="100%"/>
</figure>

<p>With this technique I was able to align my fish and feed it into my machine learning models.</p>
<p>Thanks for reading.</p>
<h5 id="disclaimer">Disclaimer</h5>
<p>I use <a href="http://stackoverflow.com/">http://stackoverflow.com/</a> a lot. Not every source is quoted properly.
Other sources:
<a href="https://www.kaggle.com/qiubit/the-nature-conservancy-fisheries-monitoring/crop-fish">https://www.kaggle.com/qiubit/the-nature-conservancy-fisheries-monitoring/crop-fish</a></p>

</content>
<p>
  
  <a href="/blog/python/">#python</a>
  
  <a href="/blog/math/">#math</a>
  
  <a href="/blog/machine-learning/">#machine learning</a>
  
  <a href="/blog/ai/">#ai</a>
  
</p>

  </main>
  <footer>
</footer>

    
</body>

</html>
