<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on </title>
    <link>https://sysid.github.io/post/</link>
    <description>Recent content in Posts on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>All rights reserved - 2016</copyright>
    <lastBuildDate>Sun, 05 Mar 2017 17:16:36 +0100</lastBuildDate>
    <atom:link href="https://sysid.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Facebook&#39;s Prophet forecasting library</title>
      <link>https://sysid.github.io/post/be-a-prophet-for-airline-data/</link>
      <pubDate>Sun, 05 Mar 2017 17:16:36 +0100</pubDate>
      
      <guid>https://sysid.github.io/post/be-a-prophet-for-airline-data/</guid>
      <description>

&lt;h1 id=&#34;be-a-prophet-for-1960-s-airline-data&#34;&gt;Be a prophet for 1960&amp;rsquo;s airline data&lt;/h1&gt;

&lt;p&gt;Facebook released a forecasting library for business timeseries, called &lt;a href=&#34;https://facebookincubator.github.io/prophet/&#34;&gt;Prophet&lt;/a&gt;. It&amp;rsquo;s designed
to work similar to the phantastic &lt;a href=&#34;phttp://scikit-learn.org/stable/&#34;&gt;scikit-learn&lt;/a&gt; library and is therefor easy to use.&lt;/p&gt;

&lt;p&gt;In order to give an example of its usefulness and effectiveness I will apply it to the good old airline passenger dataset.&lt;/p&gt;

&lt;p&gt;The input to &lt;strong&gt;Prophet&lt;/strong&gt; is always a dataframe with two columns: &lt;strong&gt;&lt;code&gt;ds&lt;/code&gt;&lt;/strong&gt; and &lt;strong&gt;&lt;code&gt;y&lt;/code&gt;&lt;/strong&gt;. The &lt;strong&gt;&lt;code&gt;ds (datestamp)&lt;/code&gt;&lt;/strong&gt; column must contain a date or datetime (either is fine). The &lt;strong&gt;&lt;code&gt;y&lt;/code&gt;&lt;/strong&gt; column must be numeric, and represents the measurement we wish to forecast.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = pd.read_csv(DATA_HOME_DIR+&#39;/international-airline-passengers.csv&#39;,
                 sep=&#39;;&#39;,
                 names=[&#39;ds&#39;, &#39;y&#39;],
                 header=0,
                 parse_dates=[0],
                 nrows=144,
                )
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Since the data seems to incorporate an exponential growth trend, we preprocess it by taking the &lt;strong&gt;&lt;code&gt;log&lt;/code&gt;&lt;/strong&gt; and use the linear
trend fitting capabilities of &lt;strong&gt;Prophet&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;y&#39;] = np.log(df[&#39;y&#39;])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We only have monthly data, so certainly there will be no weekly seasonality in the date. Forecasting must take this into account and choose the right frequency for the target dates.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;m = Prophet(weekly_seasonality=False)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can simply call the &lt;strong&gt;&lt;code&gt;fit&lt;/code&gt;&lt;/strong&gt; method in order to fit the data.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;m.fit(df)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Predictions are then made on a dataframe with a column &lt;strong&gt;&lt;code&gt;ds&lt;/code&gt;&lt;/strong&gt; containing the dates for which a prediction is to be made. You can get a suitable dataframe that extends into the future a specified number of days using the helper method &lt;strong&gt;&lt;code&gt;Prophet.make_future_dataframe&lt;/code&gt;&lt;/strong&gt;. By default it will also include the dates from the history, so we will see the model fit as well.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;future = m.make_future_dataframe(periods=36, freq=&#39;M&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;strong&gt;&lt;code&gt;predict&lt;/code&gt;&lt;/strong&gt; method will assign each row in &lt;strong&gt;&lt;code&gt;future&lt;/code&gt;&lt;/strong&gt; a predicted value which it names yhat. If you pass in historical dates, it will provide an in-sample fit. The forecast object here is a new dataframe that includes a column yhat with the forecast, as well as columns for components and uncertainty intervals.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;forecast = m.predict(future)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result is promising:

&lt;figure &gt;
    
        &lt;img src=&#34;https://sysid.github.io/images/airline_fit.png&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;Prophet automatically gives you an overall trend analysis and decomposes the time series into its constituing compontents like yearly seasonality:

&lt;figure &gt;
    
        &lt;img src=&#34;https://sysid.github.io/images/airline_comp1.png&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/p&gt;

&lt;p&gt;Seeing a almost perfect linear trend confirms the original hypothesis of having a exponential growth trend. Having a peak in July for travel numbers, it seems that the holiday season in the western hemisphere is kicking in. However this is just an asumption since I have not been born at the time and don&amp;rsquo;t know the holiday season arrangments of the time.&lt;/p&gt;

&lt;p&gt;If you are interested in another helpful example, I refer to the excellent article of Arne: &lt;a href=&#34;https://arnesund.com/2017/02/26/using-facebook-prophet-forecasting-library-to-predict-the-weather/&#34;&gt;https://arnesund.com/2017/02/26/using-facebook-prophet-forecasting-library-to-predict-the-weather/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LSTM versus MLP for timeseries</title>
      <link>https://sysid.github.io/post/adding-problem/</link>
      <pubDate>Mon, 20 Feb 2017 07:23:42 +0100</pubDate>
      
      <guid>https://sysid.github.io/post/adding-problem/</guid>
      <description>

&lt;p&gt;Long Short Term Memory neural networks versus Multi Layer Perceptrons for time series:&lt;/p&gt;

&lt;p&gt;Playing around with RNN and LSTM for time series modelling so far resulted in disappointment. Traditional MLPs seem to perform better.
On the internet RNNs are often recommended for time-series data, but my results do not confirm this sentiment. Published examples on the internet normaly do not include a comparision
with MLP models, so I decided to analyse performance of LSTM time-series forecasting versus MLP systematically.&lt;/p&gt;

&lt;p&gt;First I needed to decided on the experimental setup and I started with a dataset which migth not seem as the natural first choice for timeseries examples: The Adding Problem.&lt;/p&gt;

&lt;p&gt;My inspiration herefor was &lt;a href=&#34;http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/&#34;&gt;http://simaaron.github.io/Estimating-rainfall-from-weather-radar-readings-using-recurrent-neural-networks/&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;part-1-the-adding-problem&#34;&gt;Part 1: The Adding Problem&lt;/h3&gt;

&lt;p&gt;The prediction of cumulative values from variable-length sequences of vectors with a ‘time’ component is highly reminiscent of the so-called
&lt;em&gt;Adding Problem&lt;/em&gt;
 in machine learning—a toy sequence regression task that is designed to demonstrate the power of recurrent neural networks (RNN) in learning long-term dependencies (see
 &lt;a href=&#34;http://arxiv.org/abs/1504.00941&#34;&gt;Le et al.&lt;/a&gt;
 , Sec. 4.1, for a recent example):&lt;/p&gt;

&lt;!-- 
&lt;figure &gt;
    
        &lt;img src=&#34;https://sysid.github.io/images/RNN_adding.png&#34; /&gt;
    
    
    &lt;figcaption&gt;
        &lt;h4&gt;RNN&lt;/h4&gt;
        
    &lt;/figcaption&gt;
    
&lt;/figure&gt;
 --&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;https://sysid.github.io/images/RNN_adding.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;br&gt;
Braced with this data I started my experiments to compare LSTM with MLP &lt;a href=&#34;../../nbs/adding.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Traditional MLP models seem to yield better results for this kind of sequence problem. They converge for sequence sizes &amp;gt; 50 and seem to have lower MSE.
This leaves me wondering whether the prevalent opinion on the internet on RNNs and especially LSTMs for time series data modelling seems to be misguided.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>